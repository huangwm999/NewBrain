{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2017-12-14T04:34:57.191258Z",
     "start_time": "2017-12-14T04:34:56.647886Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import input_data\n",
    "import os\n",
    "import shutil\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2017-12-14T04:34:57.202702Z",
     "start_time": "2017-12-14T04:34:57.199718Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "img_height = 28  \n",
    "img_width = 28  \n",
    "img_size = img_height * img_width  \n",
    "  \n",
    "to_train = True  \n",
    "to_restore = False  \n",
    "output_path = \"output\"  \n",
    "  \n",
    "max_epoch = 50 \n",
    "\n",
    "h1_size = 150  \n",
    "h2_size = 300  \n",
    "z_size = 100  \n",
    "batch_size = 256  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2017-12-14T04:34:57.611110Z",
     "start_time": "2017-12-14T04:34:57.578499Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_generator(z_prior):  \n",
    "    w1 = tf.Variable(tf.truncated_normal([z_size, h1_size], stddev=0.1), name=\"g_w1\", dtype=tf.float32)  \n",
    "    b1 = tf.Variable(tf.zeros([h1_size]), name=\"g_b1\", dtype=tf.float32)  \n",
    "    h1 = tf.nn.relu(tf.matmul(z_prior, w1) + b1)  \n",
    "    w2 = tf.Variable(tf.truncated_normal([h1_size, h2_size], stddev=0.1), name=\"g_w2\", dtype=tf.float32)  \n",
    "    b2 = tf.Variable(tf.zeros([h2_size]), name=\"g_b2\", dtype=tf.float32)  \n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)  \n",
    "    w3 = tf.Variable(tf.truncated_normal([h2_size, img_size], stddev=0.1), name=\"g_w3\", dtype=tf.float32)  \n",
    "    b3 = tf.Variable(tf.zeros([img_size]), name=\"g_b3\", dtype=tf.float32)  \n",
    "    h3 = tf.matmul(h2, w3) + b3  \n",
    "    x_generate = tf.nn.tanh(h3)  \n",
    "    g_params = [w1, b1, w2, b2, w3, b3]  \n",
    "    return x_generate, g_params  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2017-12-14T04:34:57.713271Z",
     "start_time": "2017-12-14T04:34:57.691982Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_discriminator(x_data, x_generated, keep_prob):  \n",
    "    x_in = tf.concat([x_data], 0)  \n",
    "    w1 = tf.Variable(tf.truncated_normal([img_size, h2_size], stddev=0.1), name=\"d_w1\", dtype=tf.float32)  \n",
    "    b1 = tf.Variable(tf.zeros([h2_size]), name=\"d_b1\", dtype=tf.float32)  \n",
    "    h1 = tf.nn.dropout(tf.nn.relu(tf.matmul(x_in, w1) + b1), keep_prob)\n",
    "    \n",
    "    w2 = tf.Variable(tf.truncated_normal([h2_size, h1_size], stddev=0.1), name=\"d_w2\", dtype=tf.float32)  \n",
    "    b2 = tf.Variable(tf.zeros([h1_size]), name=\"d_b2\", dtype=tf.float32)  \n",
    "    h2 = tf.nn.dropout(tf.nn.relu(tf.matmul(h1, w2) + b2), keep_prob)  \n",
    "    \n",
    "    w3 = tf.Variable(tf.truncated_normal([h1_size, 1], stddev=0.1), name=\"d_w3\", dtype=tf.float32)  \n",
    "    b3 = tf.Variable(tf.zeros([1]), name=\"d_b3\", dtype=tf.float32)  \n",
    "    h3 = tf.matmul(h2, w3) + b3  \n",
    "    y_data = tf.nn.sigmoid(h3)\n",
    "    \n",
    "    x_in = tf.concat([x_generated], 0)  \n",
    "    h1 = tf.nn.dropout(tf.nn.relu(tf.matmul(x_in, w1) + b1), keep_prob)\n",
    "    h2 = tf.nn.dropout(tf.nn.relu(tf.matmul(h1, w2) + b2), keep_prob)  \n",
    "    h3 = tf.matmul(h2, w3) + b3  \n",
    "    y_generated = tf.nn.sigmoid(h3)\n",
    "    d_params = [w1, b1, w2, b2, w3, b3]  \n",
    "    \n",
    "    return y_data, y_generated, d_params  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2017-12-14T04:34:57.835952Z",
     "start_time": "2017-12-14T04:34:57.827334Z"
    },
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "def imsave(path,images):\n",
    "    return scipy.misc.imsave(path, images)\n",
    "def show_result(batch_res, fname, grid_size=(8, 8), grid_pad=5):  \n",
    "    batch_res = 0.5 * batch_res.reshape((batch_res.shape[0], img_height, img_width)) + 0.5  \n",
    "    img_h, img_w = batch_res.shape[1], batch_res.shape[2]  \n",
    "    grid_h = img_h * grid_size[0] + grid_pad * (grid_size[0] - 1)  \n",
    "    grid_w = img_w * grid_size[1] + grid_pad * (grid_size[1] - 1)  \n",
    "    img_grid = np.zeros((grid_h, grid_w), dtype=np.uint8)  \n",
    "    for i, res in enumerate(batch_res):  \n",
    "        if i >= grid_size[0] * grid_size[1]:  \n",
    "            break  \n",
    "        img = (res) * 255  \n",
    "        img = img.astype(np.uint8)  \n",
    "        row = (i // grid_size[0]) * (img_h + grid_pad)  \n",
    "        col = (i % grid_size[1]) * (img_w + grid_pad)  \n",
    "        img_grid[row:row + img_h, col:col + img_w] = img  \n",
    "    imsave(fname, img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2017-12-14T04:37:37.801938Z",
     "start_time": "2017-12-14T04:37:37.761571Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():  \n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)  \n",
    "  \n",
    "    x_data = tf.placeholder(tf.float32, [batch_size, img_size], name=\"x_data\")  \n",
    "    z_prior = tf.placeholder(tf.float32, [batch_size, z_size], name=\"z_prior\")  \n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")  \n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)  \n",
    "  \n",
    "    x_generated, g_params = build_generator(z_prior)  \n",
    "    y_data, y_generated, d_params = build_discriminator(x_data, x_generated, keep_prob)  \n",
    "  \n",
    "    d_loss = - (tf.log(y_data) + tf.log(1 - y_generated))  \n",
    "    g_loss = - tf.log(y_generated)  \n",
    "  \n",
    "    optimizerd = tf.train.AdamOptimizer(0.0001)  \n",
    "    optimizerg = tf.train.AdamOptimizer(0.0001)  \n",
    "  \n",
    "    d_trainer = optimizerd.minimize(d_loss, var_list=d_params)  \n",
    "    g_trainer = optimizerg.minimize(g_loss, var_list=g_params)  \n",
    "  \n",
    "    init = tf.global_variables_initializer()  \n",
    "  \n",
    "    saver = tf.train.Saver()  \n",
    "  \n",
    "    sess = tf.Session()  \n",
    "  \n",
    "    sess.run(init)  \n",
    "  \n",
    "    if to_restore:  \n",
    "        chkpt_fname = tf.train.latest_checkpoint(output_path)  \n",
    "        saver.restore(sess, chkpt_fname)  \n",
    "    else:  \n",
    "        if os.path.exists(output_path):  \n",
    "            shutil.rmtree(output_path)  \n",
    "        os.mkdir(output_path)  \n",
    "  \n",
    "    \n",
    "  \n",
    "    for i in range(sess.run(global_step), max_epoch):  \n",
    "        for j in range(60000 / batch_size):  \n",
    "            x_value, _ = mnist.train.next_batch(batch_size)  \n",
    "            x_value = 2 * x_value.astype(np.float32) - 1  \n",
    "            z_value = x_value[:,200:300];#np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)  \n",
    "            _,d_l=sess.run([d_trainer,d_loss],  \n",
    "                     feed_dict={x_data: x_value, z_prior: z_value, keep_prob: np.sum(0.7).astype(np.float32)})  \n",
    "            #if j % 1 == 0:  \n",
    "            _,g_l=sess.run([g_trainer,g_loss],  \n",
    "                         feed_dict={x_data: x_value, z_prior: z_value, keep_prob: np.sum(0.7).astype(np.float32)}) \n",
    "        #print np.mean(g_l)\n",
    "        if(i%10==0) :\n",
    "                print \"epoch:%s, d_loss:%f,g_loss:%f\" % (i, np.exp(-np.mean(d_l) ),np.exp(-np.mean(g_l) ) )  \n",
    "        if (i%50==0):\n",
    "            z_sample_val = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)  \n",
    "            x_gen_val = sess.run(x_generated, feed_dict={z_prior: z_sample_val})  \n",
    "            show_result(x_gen_val, os.path.join(output_path, \"sample%s.jpg\" % i))  \n",
    "            z_random_sample_val = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)  \n",
    "            x_gen_val = sess.run(x_generated, feed_dict={z_prior: z_random_sample_val})  \n",
    "            show_result(x_gen_val, os.path.join(output_path, \"random_sample%s.jpg\" % i))  \n",
    "            sess.run(tf.assign(global_step, i + 1))  \n",
    "            saver.save(sess, os.path.join(output_path, \"model\"), global_step=global_step)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2017-12-14T04:38:16.661897Z",
     "start_time": "2017-12-14T04:37:56.134974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "epoch:0, d_loss:0.297412,g_loss:0.176079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, d_loss:0.599504,g_loss:0.106864\n",
      "epoch:20, d_loss:0.692884,g_loss:0.043911\n",
      "epoch:30, d_loss:0.584611,g_loss:0.034425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-29e870ccb38d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m210\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-46fd9190b343>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m#if j % 1 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             _,g_l=sess.run([g_trainer,g_loss],  \n\u001b[0;32m---> 48\u001b[0;31m                          feed_dict={x_data: x_value, z_prior: z_value, keep_prob: np.sum(0.7).astype(np.float32)}) \n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m#print np.mean(g_l)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epoch = 210\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
